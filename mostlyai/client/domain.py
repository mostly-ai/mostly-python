# generated by datamodel-codegen:
#   timestamp: 2024-12-15T22:38:22+00:00

from __future__ import annotations

from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Annotated, Any, ClassVar, Dict, List, Literal, Optional, Union

import pandas as pd
from pydantic import Field, RootModel, field_validator

from mostlyai.client._base_utils import convert_to_base64
from mostlyai.client.base import CustomBaseModel


class PermissionLevel(str, Enum):
    """
    The permission level of the user or group with respect to this entity
    - VIEW: The user can view and use the entity
    - EDIT: The user can edit and share the entity
    - ADMIN: The user can edit, share and delete the entity
    There is only a single user per entity with ADMIN rights, and that user is the owner of the entity.

    """

    view = "VIEW"
    edit = "EDIT"
    admin = "ADMIN"


class UserSettingsProfileUpdateConfig(CustomBaseModel):
    first_name: Optional[str] = Field(
        None, alias="firstName", description="First name of a user", max_length=30
    )
    last_name: Optional[str] = Field(
        None, alias="lastName", description="Last name of a user", max_length=30
    )


class UserSettingsAssistantUpdateConfig(CustomBaseModel):
    about_user_message: Optional[str] = Field(
        None,
        alias="aboutUserMessage",
        description="The instruction what the Assistant should know about the user to provide better response",
    )
    about_model_message: Optional[str] = Field(
        None,
        alias="aboutModelMessage",
        description="The instruction how the Assistant should respond",
    )


class Credits(CustomBaseModel):
    current: Optional[float] = Field(
        None, description="The credit balance for the current time period"
    )
    limit: Optional[float] = Field(
        None,
        description="The credit limit for the current time period. If empty, then there is no limit.",
    )
    period_start: Optional[datetime] = Field(
        None,
        alias="periodStart",
        description="The UTC date and time when the current time period started",
    )
    period_end: Optional[datetime] = Field(
        None,
        alias="periodEnd",
        description="The UTC date and time when the current time period ends",
    )


class ParallelTrainingJobs(CustomBaseModel):
    current: Optional[int] = Field(
        None, description="The number of currently running training jobs"
    )
    limit: Optional[int] = Field(
        None,
        description="The maximum number of running training jobs at any time. If empty, then there is no limit.",
    )


class ParallelGenerationJobs(CustomBaseModel):
    current: Optional[int] = Field(
        None, description="The number of currently running generation jobs"
    )
    limit: Optional[int] = Field(
        None,
        description="The maximum number of running generation jobs at any time. If empty, then there is no limit.",
    )


class UserUsage(CustomBaseModel):
    credits: Optional[Credits] = None
    parallel_training_jobs: Optional[ParallelTrainingJobs] = Field(
        None, alias="parallelTrainingJobs"
    )
    parallel_generation_jobs: Optional[ParallelGenerationJobs] = Field(
        None, alias="parallelGenerationJobs"
    )


class NotificationStatus(str, Enum):
    """
    The status of the notification
    """

    unread = "UNREAD"
    read = "READ"


class NotificationType(str, Enum):
    """
    The type of the notification
    """

    resource_ready = "RESOURCE_READY"
    resource_shared = "RESOURCE_SHARED"
    resource_liked = "RESOURCE_LIKED"
    resource_failed = "RESOURCE_FAILED"


class Metadata(CustomBaseModel):
    created_at: Optional[datetime] = Field(
        None,
        alias="createdAt",
        description="The UTC date and time when the resource has been created.\n",
        examples=["2023‐09‐07T18:40:39Z"],
    )
    owner_id: Optional[str] = Field(
        None,
        alias="ownerId",
        description="The unique identifier of the owner of the entity",
    )
    owner_name: Optional[str] = Field(
        None, alias="ownerName", description="The name of the owner of the entity"
    )
    current_user_permission_level: Optional[PermissionLevel] = Field(
        None, alias="currentUserPermissionLevel"
    )
    current_user_like_status: Optional[bool] = Field(
        None,
        alias="currentUserLikeStatus",
        description="A boolean indicating whether the user has liked the entity or not",
    )
    short_lived_file_token: Optional[str] = Field(
        None,
        alias="shortLivedFileToken",
        description="An auto-generated short-lived file token (`slft`) for accessing resource artefacts.\nThe token is always restricted to a single resource, only valid for 60 minutes, and \nonly accepted by API endpoints that allow to download single files.\n",
    )


class PaginatedTotalCount(RootModel[int]):
    root: int = Field(..., description="The total number of entities within the list")


class ModelEncodingType(str, Enum):
    """
    The encoding type used for model training and data generation.

    - `AUTO`: Model chooses among available encoding types based on the column's data type.
    - `TABULAR_CATEGORICAL`: Model samples from existing (non-rare) categories.
    - `TABULAR_NUMERIC_AUTO`: Model chooses among 3 numeric encoding types based on the values.
    - `TABULAR_NUMERIC_DISCRETE`: Model samples from existing discrete numerical values.
    - `TABULAR_NUMERIC_BINNED`: Model samples from binned buckets, to then sample randomly within a bucket.
    - `TABULAR_NUMERIC_DIGIT`: Model samples each digit of a numerical value.
    - `TABULAR_CHARACTER`: Model samples each character of a string value.
    - `TABULAR_DATETIME`: Model samples each part of a datetime value.
    - `TABULAR_DATETIME_RELATIVE`: Model samples the relative difference between datetimes within a sequence.
    - `TABULAR_LAT_LONG`: Model samples a latitude-longitude column. The format is "latitude,longitude".
    - `LANGUAGE_TEXT`: Model will train a distinct LANGUAGE model for this column, to then generate free text.

    Encoding types, that are not being prefixed with either `TABULAR` or `LANGUAGE` have been deprecated.

    """

    auto = "AUTO"
    tabular_categorical = "TABULAR_CATEGORICAL"
    tabular_numeric_auto = "TABULAR_NUMERIC_AUTO"
    tabular_numeric_discrete = "TABULAR_NUMERIC_DISCRETE"
    tabular_numeric_binned = "TABULAR_NUMERIC_BINNED"
    tabular_numeric_digit = "TABULAR_NUMERIC_DIGIT"
    tabular_character = "TABULAR_CHARACTER"
    tabular_datetime = "TABULAR_DATETIME"
    tabular_datetime_relative = "TABULAR_DATETIME_RELATIVE"
    tabular_lat_long = "TABULAR_LAT_LONG"
    language_text = "LANGUAGE_TEXT"
    categorical = "CATEGORICAL"
    numeric_auto = "NUMERIC_AUTO"
    numeric_discrete = "NUMERIC_DISCRETE"
    numeric_binned = "NUMERIC_BINNED"
    numeric_digit = "NUMERIC_DIGIT"
    character = "CHARACTER"
    datetime = "DATETIME"
    datetime_relative = "DATETIME_RELATIVE"
    lat_long = "LAT_LONG"


class ConnectorAccessType(str, Enum):
    source = "SOURCE"
    destination = "DESTINATION"


class ConnectorType(str, Enum):
    mysql = "MYSQL"
    postgres = "POSTGRES"
    mssql = "MSSQL"
    oracle = "ORACLE"
    mariadb = "MARIADB"
    snowflake = "SNOWFLAKE"
    bigquery = "BIGQUERY"
    databricks = "DATABRICKS"
    azure_storage = "AZURE_STORAGE"
    google_cloud_storage = "GOOGLE_CLOUD_STORAGE"
    s3_storage = "S3_STORAGE"
    file_upload = "FILE_UPLOAD"
    hive = "HIVE"


class ConnectorUsage(CustomBaseModel):
    no_of_shares: Optional[int] = Field(
        None, alias="noOfShares", description="Number of shares of this connector."
    )
    no_of_generators: Optional[int] = Field(
        None,
        alias="noOfGenerators",
        description="Number of generators using this connector.",
    )


class ConnectorListItem(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a connector")
    name: str = Field(..., description="The name of a connector")
    type: ConnectorType
    access_type: ConnectorAccessType = Field(..., alias="accessType")
    metadata: Metadata
    usage: Optional[ConnectorUsage] = None


class Connector(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a connector")
    name: str = Field(..., description="The name of a connector")
    type: ConnectorType
    access_type: ConnectorAccessType = Field(..., alias="accessType")
    config: Optional[Dict[str, Any]] = None
    secrets: Optional[Dict[str, str]] = None
    ssl: Optional[Dict[str, str]] = None
    metadata: Optional[Metadata] = None
    usage: Optional[ConnectorUsage] = None
    table_id: Optional[str] = Field(
        None,
        alias="tableId",
        description="Optional. ID of a source table or a synthetic table, that this connector belongs to.\nIf not set, then this connector is managed independently of any generator or synthetic dataset.\n",
    )
    OPEN_URL_PARTS: ClassVar[list] = ["d", "connectors"]

    def update(
        self,
        name: Optional[str] = None,
        config: Optional[dict[str, Any]] = None,
        secrets: Optional[dict[str, str]] = None,
        ssl: Optional[dict[str, str]] = None,
        test_connection: Optional[bool] = True,
    ) -> None:
        """
        Update a connector with specific parameters.

        Args:
            name: The name of the connector.
            config (dict[str, Any], optional): Connector configuration.
            secrets (dict[str, str], optional): Secret values for the connector.
            ssl (dict[str, str], optional): SSL configuration for the connector.
            test_connection: If true, validates the connection before saving.
        """
        patch_config = ConnectorPatchConfig(
            name=name,
            config=config,
            secrets=secrets,
            ssl=ssl,
            test_connection=test_connection,
        )
        self.client._update(
            connector_id=self.id, config=patch_config.model_dump(exclude_none=True)
        )
        self.reload()

    def delete(self) -> None:
        """
        Delete the connector.

        Returns:
            None
        """
        return self.client._delete(connector_id=self.id)

    def locations(self, prefix: str = "") -> list:
        """
        List connector locations.

        List the available databases, schemas, tables, or folders for a connector.
        For storage connectors, this returns list of folders and files at root, respectively at `prefix` level.
        For DB connectors, this returns list of schemas (or databases for DBs without schema), respectively list of tables if `prefix` is provided.

        The formats of the locations are:

        - Cloud storage:
            - `AZURE_STORAGE`: `container/path`
            - `GOOGLE_CLOUD_STORAGE`: `bucket/path`
            - `S3_STORAGE`: `bucket/path`
        - Database:
            - `BIGQUERY`: `dataset.table`
            - `DATABRICKS`: `schema.table`
            - `HIVE`: `database.table`
            - `MARIADB`: `database.table`
            - `MSSQL`: `schema.table`
            - `MYSQL`: `database.table`
            - `ORACLE`: `schema.table`
            - `POSTGRES`: `schema.table`
            - `SNOWFLAKE`: `schema.table`

        Args:
            prefix: The prefix to filter the results by.

        Returns:
            list: A list of locations (schemas, databases, directories, etc.)."""
        return self.client._locations(connector_id=self.id, prefix=prefix)

    def schema(self, location: str) -> list[dict[str, Any]]:
        """
        Retrieve the schema of the table at a connector location.
        Please refer to `locations()` for the format of the location.

        Args:
            location: The location of the table.

        Returns:
            list[dict[str, Any]]: The retrieved schema.
        """
        return self.client._schema(connector_id=self.id, location=location)


class ConnectorConfig(CustomBaseModel):
    name: Optional[str] = Field(None, description="The name of a connector")
    type: ConnectorType
    access_type: Optional[ConnectorAccessType] = Field(
        ConnectorAccessType.source, alias="accessType"
    )
    config: Optional[Dict[str, Any]] = None
    secrets: Optional[Dict[str, str]] = None
    ssl: Optional[Dict[str, str]] = None
    test_connection: Optional[bool] = Field(
        None,
        alias="testConnection",
        description="If true, the connection will be tested before saving. In case of error, the connector will not be saved.\nIf false, the connection will not be tested.\n",
    )


class ConnectorPatchConfig(CustomBaseModel):
    name: Optional[str] = Field(None, description="The name of a connector")
    config: Optional[Dict[str, Any]] = None
    secrets: Optional[Dict[str, str]] = None
    ssl: Optional[Dict[str, str]] = None
    test_connection: Optional[bool] = Field(
        None,
        alias="testConnection",
        description="If true, the connection will be tested before saving. In case of error, the connector will not be saved.\nIf false, the connection will not be tested.\n",
    )


class GeneratorUsage(CustomBaseModel):
    total_datapoints: Optional[int] = Field(
        None,
        alias="totalDatapoints",
        description="The total number of datapoints generated by this generator.",
    )
    total_compute_time: Optional[int] = Field(
        None,
        alias="totalComputeTime",
        description="The total compute time in seconds used for training this generator.\nThis is the sum of the compute time of all trained tasks.\n",
    )
    no_of_synthetic_datasets: Optional[int] = Field(
        None,
        alias="noOfSyntheticDatasets",
        description="Number of synthetic datasets generated by this generator.",
    )
    no_of_shares: Optional[int] = Field(
        None, alias="noOfShares", description="Number of shares of this generator."
    )
    no_of_likes: Optional[int] = Field(
        None, alias="noOfLikes", description="Number of likes of this generator."
    )


class SourceColumnValueRange(CustomBaseModel):
    """
    The (privacy-safe) range of values detected within a source column. These values can then be used as seed values
    for conditional generation. For CATEGORICAL and NUMERIC_DISCRETE encoding types, this will be given as a list
    of unique values, sorted by popularity. For other NUMERIC and for DATETIME encoding types, this will be given
    as a min and max value. Note, that this property will only be populated, once the analysis step for the training
    of the generator has been completed.

    """

    min: Optional[str] = Field(
        None,
        description="The minimum value of the column. For dates, this is represented in ISO format.",
    )
    max: Optional[str] = Field(
        None,
        description="The maximum value of the column. For dates, this is represented in ISO format.",
    )
    values: Optional[List[str]] = Field(
        None,
        description="The list of distinct values of the column. Limited to a maximum of 1000 values.",
    )
    has_null: Optional[bool] = Field(
        None, description="If true, null value was detected within the column."
    )


class SourceColumn(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a source column")
    name: str = Field(..., description="The name of a source column")
    included: bool = Field(
        ...,
        description="If true, the column will be included in the training.\nIf false, the column will be excluded from the training.\n",
    )
    model_encoding_type: ModelEncodingType = Field(..., alias="modelEncodingType")
    value_range: Optional[SourceColumnValueRange] = Field(None, alias="valueRange")


class SourceForeignKey(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a foreign key")
    column: Optional[str] = Field(None, description="The column name of a foreign key.")
    referenced_table: str = Field(
        ...,
        alias="referencedTable",
        description="The table name of the referenced table. That table must have a primary key already defined.",
    )
    is_context: bool = Field(
        ...,
        alias="isContext",
        description="If true, then the foreign key will be considered as a context relation.\nNote, that only one foreign key relation per table can be a context relation.\n",
    )


class GeneratorCloneTrainingStatus(Enum):
    """
    The training status of the new generator. The available options are:

    - `NEW`: The new generator will re-use existing data and model configurations.
    - `CONTINUE`: The new generator will re-use existing data and model configurations, as well as model weights.

    """

    new = "NEW"
    continue_ = "CONTINUE"


class GeneratorPatchConfig(CustomBaseModel):
    """
    The configuration for updating a generator.
    """

    name: Optional[str] = Field(None, description="The name of a generator")
    description: Optional[str] = Field(
        None, description="The description of a generator"
    )


class GeneratorImportFromFileConfig(CustomBaseModel):
    file: bytes


class SourceForeignKeyConfig(CustomBaseModel):
    column: str = Field(..., description="The column name of a foreign key.")
    referenced_table: str = Field(
        ...,
        alias="referencedTable",
        description="The table name of the referenced table. That table must have a primary key already defined.",
    )
    is_context: Optional[bool] = Field(
        None,
        alias="isContext",
        description="If true, then the foreign key will be considered as a context relation.\nNote, that only one foreign key relation per table can be a context relation.\n",
    )


class SourceForeignKeyPatchConfig(CustomBaseModel):
    is_context: Optional[bool] = Field(
        None,
        alias="isContext",
        description="If true, then the foreign key will be considered as a context relation.\nNote, that only one foreign key relation per table can be a context relation.\n",
    )


class SourceColumnConfig(CustomBaseModel):
    name: str = Field(..., description="The name of a source column")
    included: Optional[bool] = Field(
        None,
        description="If true, the column will be included in the training.\nIf false, the column will be excluded from the training.\n",
    )
    model_encoding_type: Optional[ModelEncodingType] = Field(
        ModelEncodingType.auto, alias="modelEncodingType"
    )


class SourceColumnPatchConfig(CustomBaseModel):
    included: Optional[bool] = Field(
        None,
        description="If true, the column will be included in the training.\nIf false, the column will be excluded from the training.\n",
    )
    model_encoding_type: Optional[ModelEncodingType] = Field(
        ModelEncodingType.auto, alias="modelEncodingType"
    )


class ModelType(str, Enum):
    tabular = "TABULAR"
    language = "LANGUAGE"


class RareCategoryReplacementMethod(str, Enum):
    """
    Specifies, if the rare categories for categoricals will be replaced by a constant
    _RARE_ or by a sample from non-rare categories.
    Only applicable if valueProtection is set to True.

    """

    constant = "CONSTANT"
    sample = "SAMPLE"


class ModelConfigurationDifferentialPrivacy(CustomBaseModel):
    """
    The optional differential privacy configuration for training the model.
    If not provided, then no differential privacy will be applied.

    """

    max_epsilon: Optional[float] = Field(
        None,
        alias="maxEpsilon",
        description="Specifies the maximum allowable epsilon value. If the training process exceeds this threshold, it will be terminated early. Only model checkpoints with epsilon values below this limit will be retained. \nIf not provided, the training will proceed without early termination based on epsilon constraints.\n",
        ge=0.0,
        le=10000.0,
    )
    noise_multiplier: Optional[float] = Field(
        1.5,
        alias="noiseMultiplier",
        description="The ratio of the standard deviation of the Gaussian noise to the L2-sensitivity of the function to which the noise is added (How much noise to add).\n",
        ge=0.0,
        le=10000.0,
    )
    max_grad_norm: Optional[float] = Field(
        1.0,
        alias="maxGradNorm",
        description="The maximum norm of the per-sample gradients for training the model with differential privacy.\n",
        ge=0.0,
        le=10000.0,
    )


class Accuracy(CustomBaseModel):
    overall: Optional[float] = Field(
        None,
        description="The overall accuracy of the model.\nThis is the average of univariate, bivariate and coherence accuracies.\nAccuracy is defined as (100% - Total Variation Distance) for each distribution, and then averaged across.\n",
        ge=0.0,
        le=1.0,
    )
    univariate: Optional[float] = Field(
        None,
        description="The average accuracy of the discretized univariate distributions.\n",
        ge=0.0,
        le=1.0,
    )
    bivariate: Optional[float] = Field(
        None,
        description="The average accuracy of the discretized bivariate distributions.\n",
        ge=0.0,
        le=1.0,
    )
    coherence: Optional[float] = Field(
        None,
        description="The average accuracy of the discretized coherence distributions.\nOnly applicable for sequential models.\n",
        ge=0.0,
        le=1.0,
    )
    overall_max: Optional[float] = Field(
        None,
        alias="overallMax",
        description="The expected accuracy of a holdout dataset of same size as synthetic dataset.\nThis serves as a reference for the overall accuracy of the trained generator.\n",
        ge=0.0,
        le=1.0,
    )


class Distances(CustomBaseModel):
    dcr_training: Optional[float] = Field(
        None,
        alias="dcrTraining",
        description="The average distance to closest record (L2) between synthetic and training samples within the embedding space.",
        ge=0.0,
    )
    dcr_holdout: Optional[float] = Field(
        None,
        alias="dcrHoldout",
        description="The average distance to closest record (L2) between synthetic and holdout samples within the embedding space.",
        ge=0.0,
    )
    dcr_original: Optional[float] = Field(
        None,
        alias="dcrOriginal",
        description="(DEPRECATED) The average DCR between the original records.",
        ge=0.0,
    )
    dcr_synthetic: Optional[float] = Field(
        None,
        alias="dcrSynthetic",
        description="(DEPRECATED) The average DCR between the synthetic and the original records.",
        ge=0.0,
    )


class Similarity(CustomBaseModel):
    cosine_similarity_training_synthetic: Optional[float] = Field(
        None,
        alias="cosineSimilarityTrainingSynthetic",
        description="The cosine similarity between the training samples centroid and the synthetic samples centroid within the embedding space.",
        ge=-1.0,
        le=1.0,
    )
    cosine_similarity_training_holdout: Optional[float] = Field(
        None,
        alias="cosineSimilarityTrainingHoldout",
        description="The cosine similarity between the training samples centroid and the holdout samples centroid within the embedding space.",
        ge=-1.0,
        le=1.0,
    )
    discriminator_auc_training_synthetic: Optional[float] = Field(
        None,
        alias="discriminatorAUCTrainingSynthetic",
        description="The cross-validated average AUC of discriminating between training embeddings ans synthetic embeddings.",
        ge=0.0,
        le=1.0,
    )
    discriminator_auc_training_holdout: Optional[float] = Field(
        None,
        alias="discriminatorAUCTrainingHoldout",
        description="The cross-validated average AUC of discriminating between training embeddings ans holdout embeddings.",
        ge=0.0,
        le=1.0,
    )


class ModelMetrics(CustomBaseModel):
    accuracy: Optional[Accuracy] = None
    distances: Optional[Distances] = None
    similarity: Optional[Similarity] = None


class StepCode(str, Enum):
    pull_training_data = "PULL_TRAINING_DATA"
    analyze_training_data = "ANALYZE_TRAINING_DATA"
    encode_training_data = "ENCODE_TRAINING_DATA"
    train_model = "TRAIN_MODEL"
    generate_model_report_data = "GENERATE_MODEL_REPORT_DATA"
    create_model_report = "CREATE_MODEL_REPORT"
    finalize_training = "FINALIZE_TRAINING"
    pull_context_data = "PULL_CONTEXT_DATA"
    generate_data = "GENERATE_DATA"
    create_data_report = "CREATE_DATA_REPORT"
    finalize_generation = "FINALIZE_GENERATION"
    deliver_data = "DELIVER_DATA"


class ProgressValue(CustomBaseModel):
    value: Optional[int] = None
    max: Optional[int] = None


class ProgressStatus(str, Enum):
    """
    The status of a job or a step.
    NEW: The job/step is being configured, and has not started yet
    CONTINUE: The job/step is being configured, but has existing artefacts
    ON_HOLD: The job/step has been started, but is kept on hold
    QUEUED: The job/step has been started, and is awaiting for resources to execute
    IN_PROGRESS: The job/step is currently running
    DONE: The job/step has finished successfully
    FAILED: The job/step has failed
    CANCELED: The job/step has been canceled

    """

    new = "NEW"
    continue_ = "CONTINUE"
    on_hold = "ON_HOLD"
    queued = "QUEUED"
    in_progress = "IN_PROGRESS"
    done = "DONE"
    failed = "FAILED"
    canceled = "CANCELED"


class SyntheticDatasetUsage(CustomBaseModel):
    total_datapoints: Optional[int] = Field(
        None,
        alias="totalDatapoints",
        description="The number of datapoints in the synthetic dataset",
    )
    total_credits: Optional[float] = Field(
        None,
        alias="totalCredits",
        description="The number of credits used for the synthetic dataset",
    )
    total_compute_time: Optional[int] = Field(
        None,
        alias="totalComputeTime",
        description="The total compute time in seconds used for generating this synthetic dataset.\nThis is the sum of the compute time of all trained tasks.\n",
    )
    no_of_shares: Optional[int] = Field(
        None,
        alias="noOfShares",
        description="Number of shares of this synthetic dataset.",
    )
    no_of_likes: Optional[int] = Field(
        None,
        alias="noOfLikes",
        description="Number of likes of this synthetic dataset.",
    )


class SyntheticDatasetListItem(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a synthetic dataset")
    metadata: Metadata
    name: str = Field(..., description="The name of a synthetic dataset")
    description: Optional[str] = Field(
        None, description="The description of a synthetic dataset"
    )
    generation_status: ProgressStatus = Field(..., alias="generationStatus")
    generation_time: Optional[datetime] = Field(
        None,
        alias="generationTime",
        description="The UTC date and time when the generation has finished.",
    )
    usage: Optional[SyntheticDatasetUsage] = None


class SyntheticDatasetFormat(str, Enum):
    csv = "CSV"
    parquet = "PARQUET"
    xlsx = "XLSX"


class SyntheticDatasetReportType(str, Enum):
    model = "MODEL"
    data = "DATA"


class SyntheticTableRebalancing(CustomBaseModel):
    """
    Configure rebalancing of the table.
    Only applicable for categorical columns of a subject table.

    """

    column: Optional[str] = Field(
        None,
        description="The name of the column to be rebalanced.\nThat column must be of modelEncodingType CATEGORICAL.\n",
    )
    probabilities: Optional[Dict[str, float]] = Field(
        None,
        description="The target distribution of samples values.\nThe keys are the categorical values, and the values are the probabilities.\n",
        examples=[[{"US": 0.8}, {"male": 0.5, "female": 0.5}]],
    )


class SyntheticTableFairness(CustomBaseModel):
    """
    Configure a fairness objective for the table. Only applicable for a subject table.
    The generated synthetic data will maintain robust statistical parity between the target column and
    the specified sensitive columns. All these columns must be categorical.

    """

    target_column: str = Field(..., alias="targetColumn")
    sensitive_columns: List[str] = Field(..., alias="sensitiveColumns")


class ForeignKey(CustomBaseModel):
    column: str = Field(..., description="The column name of a foreign key.")
    referenced_table: str = Field(
        ...,
        alias="referencedTable",
        description="The table name of the referenced table. That table must have a primary key already defined.",
    )
    is_context: bool = Field(
        ...,
        alias="isContext",
        description="If true, then the foreign key will be considered as a context relation.\nNote, that only one foreign key relation per table can be a context relation.\n",
    )


class SyntheticDatasetDelivery(CustomBaseModel):
    overwrite_tables: bool = Field(
        ...,
        alias="overwriteTables",
        description="If true, tables in the destination will be overwritten.\nIf false, any tables exist, the delivery will fail.\n",
    )
    destination_connector_id: str = Field(
        ...,
        alias="destinationConnectorId",
        description="The unique identifier of a connector",
    )
    location: str = Field(
        ..., description="The location for the destination connector."
    )


class SyntheticDatasetPatchConfig(CustomBaseModel):
    name: Optional[str] = Field(None, description="The name of a synthetic dataset")
    description: Optional[str] = Field(
        None, description="The description of a synthetic dataset"
    )
    delivery: Optional[SyntheticDatasetDelivery] = None


class AssistantLiteLlmExtraItem(CustomBaseModel):
    key: Optional[str] = None
    value: Optional[str] = None


class LiteLlm(CustomBaseModel):
    model: Optional[str] = Field(
        None,
        description="The LiteLLM model of the assistant. See https://docs.litellm.ai/docs/providers.",
        examples=[["openai/gpt-3.5-turbo", "mistral/mistral-tiny"]],
    )
    api_key: Optional[str] = Field(
        None,
        alias="apiKey",
        description="The API key for the selected LiteLLM model. See https://docs.litellm.ai/docs/providers.",
    )
    extra: Optional[List[AssistantLiteLlmExtraItem]] = Field(
        None,
        description="Any additional configuration parameters for the selected LiteLLM model. See https://docs.litellm.ai/docs/providers.",
    )


class DataLlm(CustomBaseModel):
    api_key: Optional[str] = Field(
        None,
        alias="apiKey",
        description="The API key for the DataLLM service. See https://data.mostly.ai.",
    )


class AssistantSettings(CustomBaseModel):
    """
    Additional optional assistant settings used for LiteLLM
    """

    is_enabled: Optional[bool] = Field(
        None, alias="isEnabled", description="If true, the assistant is enabled."
    )
    lite_llm: Optional[LiteLlm] = Field(None, alias="liteLlm")
    data_llm: Optional[DataLlm] = Field(None, alias="dataLlm")
    system_instructions: Optional[str] = Field(
        None,
        alias="systemInstructions",
        description="The system instructions of the assistant",
    )
    custom_instructions: Optional[str] = Field(
        None,
        alias="customInstructions",
        description="The custom instructions of the assistant",
    )
    default_system_instructions: Optional[str] = Field(
        None,
        alias="defaultSystemInstructions",
        description="The system instructions of the assistant",
    )


class AssistantThreadSessionStatus(str, Enum):
    initializing = "initializing"
    running = "running"
    expired = "expired"


class AssistantTokenUsage(RootModel[float]):
    root: float


class AssistantMessageRole(str, Enum):
    """
    The role of the author of this message
    """

    system = "system"
    user = "user"
    assistant = "assistant"
    tool = "tool"
    heartbeat = "heartbeat"


class AssistantMessageContentType(str, Enum):
    """
    The type of the message content
    """

    text = "text"
    python = "python"
    console = "console"
    file = "file"


class AssistantMessageFinishReason(str, Enum):
    stop = "stop"
    length = "length"
    tool_calls = "tool_calls"


class AssistantMessage(CustomBaseModel):
    """
    A complete message.
    """

    id: Optional[str] = Field(
        None, description="The unique identifier of a assistant message"
    )
    role: Optional[AssistantMessageRole] = None
    content_type: Optional[AssistantMessageContentType] = Field(
        None, alias="contentType"
    )
    content: Optional[str] = Field(
        None, description="The content of a message", max_length=65000, min_length=0
    )
    finish_reason: Optional[AssistantMessageFinishReason] = Field(
        None, alias="finishReason"
    )
    tokens_consumed: Optional[float] = Field(
        None,
        alias="tokensConsumed",
        description="The number of tokens consumed by the assistant message.",
    )


class AssistantMessageDelta(CustomBaseModel):
    """
    A partial message delta generated by streamed model responses.
    """

    id: Optional[str] = Field(
        None, description="The unique identifier of a assistant message"
    )
    role: Optional[AssistantMessageRole] = None
    content_type: Optional[AssistantMessageContentType] = Field(
        None, alias="contentType"
    )
    delta: Optional[str] = Field(
        None,
        description="The partial content of a message",
        max_length=65000,
        min_length=1,
    )
    finish_reason: Optional[AssistantMessageFinishReason] = Field(
        None, alias="finishReason"
    )
    tokens_consumed: Optional[float] = Field(
        None,
        alias="tokensConsumed",
        description="The number of tokens consumed by the model.",
    )


class AssistantThreadUsage(CustomBaseModel):
    no_of_shares: Optional[int] = Field(
        None,
        alias="noOfShares",
        description="Number of shares of this assistant thread.",
    )
    total_tokens_consumed: Optional[float] = Field(
        None,
        alias="totalTokensConsumed",
        description="The total number of tokens consumed by the thread.",
    )


class AssistantThreadConfig(CustomBaseModel):
    name: Optional[str] = Field(None, description="The name of a assistant thread")


class AssistantThreadPatchConfig(CustomBaseModel):
    name: Optional[str] = Field(None, description="The name of a assistant thread")


class AssistantMessageConfig(CustomBaseModel):
    """
    Submit a new message
    """

    stream: Optional[bool] = Field(
        True,
        description="Whether to stream back partial progress. If set, message deltas will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a data: [DONE] message.",
    )
    content: Optional[str] = Field(
        None, description="The content of a message", max_length=65000, min_length=0
    )
    content_type: Optional[AssistantMessageContentType] = Field(
        None, alias="contentType"
    )


class ComputeType(str, Enum):
    kubernetes = "KUBERNETES"
    databricks = "DATABRICKS"


class ComputeResources(CustomBaseModel):
    cpus: Optional[int] = Field(None, description="The number of CPU cores")
    memory: Optional[float] = Field(None, description="The amount of memory in GB")
    gpus: Optional[int] = Field(0, description="The number of GPUs")
    gpu_memory: Optional[float] = Field(
        0, alias="gpuMemory", description="The amount of GPU memory in GB"
    )


class ComputeListItem(CustomBaseModel):
    id: Optional[str] = None
    type: Optional[ComputeType] = None
    name: Optional[str] = None
    resources: Optional[ComputeResources] = None


class Compute(CustomBaseModel):
    id: Optional[str] = None
    name: Optional[str] = None
    type: Optional[ComputeType] = None
    config: Optional[Dict[str, Any]] = None
    secrets: Optional[Dict[str, Any]] = None
    resources: Optional[ComputeResources] = None
    order_index: Optional[int] = Field(
        None,
        alias="orderIndex",
        description="The index for determining the sort order when listing computes",
    )


class ComputeConfig(CustomBaseModel):
    name: Optional[str] = None
    type: Optional[ComputeType] = None
    resources: Optional[ComputeResources] = None
    config: Optional[Dict[str, Any]] = None
    secrets: Optional[Dict[str, Any]] = None
    order_index: Optional[int] = Field(
        None,
        alias="orderIndex",
        description="The index for determining the sort order when listing computes",
    )


class ComputePatchConfig(CustomBaseModel):
    name: Optional[str] = None
    type: Optional[ComputeType] = None
    resources: Optional[ComputeResources] = None
    config: Optional[Dict[str, Any]] = None
    secrets: Optional[Dict[str, Any]] = None
    order_index: Optional[int] = Field(
        None,
        alias="orderIndex",
        description="The index for determining the sort order when listing computes",
    )


class UsageReportPeriod(CustomBaseModel):
    """
    The usage report for a specific month
    """

    period_start: Optional[datetime] = Field(
        None,
        alias="periodStart",
        description="The UTC date and time when the reported time period started",
    )
    period_end: Optional[datetime] = Field(
        None,
        alias="periodEnd",
        description="The UTC date and time when the reported time period started",
    )
    total_datapoints: Optional[int] = Field(
        None,
        alias="totalDatapoints",
        description="The number of datapoints generated during the reported period",
    )
    total_rows: Optional[int] = Field(
        None,
        alias="totalRows",
        description="The number of rows generated during the reported period",
    )
    total_credits: Optional[float] = Field(
        None,
        alias="totalCredits",
        description="The number of credits used during the reported period",
    )


class BaseResource(CustomBaseModel):
    id: Optional[str] = Field(None, description="The unique identifier of the entity")
    name: Optional[str] = Field(None, description="The name of the entity")
    uri: Optional[str] = Field(
        None,
        description="The API service endpoint of the entity",
        examples=["/generators/94c77249-42bf-443a-8e17-6e18a19d60b8"],
    )
    current_user_permission_level: Optional[PermissionLevel] = Field(
        None, alias="currentUserPermissionLevel"
    )
    current_user_like_status: Optional[bool] = Field(
        None,
        alias="currentUserLikeStatus",
        description="A boolean indicating whether the user has liked the entity or not",
    )


class ShareConfig(CustomBaseModel):
    user_email: str = Field(..., alias="userEmail", description="The email of a user")
    permission_level: PermissionLevel = Field(..., alias="permissionLevel")


class ShareDeleteConfig(CustomBaseModel):
    user_email: str = Field(..., alias="userEmail", description="The email of a user")


class User(CustomBaseModel):
    id: Optional[str] = Field(None, description="The unique identifier of a user")
    first_name: Optional[str] = Field(
        None, alias="firstName", description="First name of a user", max_length=30
    )
    last_name: Optional[str] = Field(
        None, alias="lastName", description="Last name of a user", max_length=30
    )
    email: Optional[str] = Field(None, description="The email of a user")


class CurrentUser(CustomBaseModel):
    id: Optional[str] = Field(None, description="The unique identifier of a user")
    first_name: Optional[str] = Field(
        None, alias="firstName", description="First name of a user", max_length=30
    )
    last_name: Optional[str] = Field(
        None, alias="lastName", description="Last name of a user", max_length=30
    )
    email: Optional[str] = Field(None, description="The email of a user")
    settings: Optional[Dict[str, Any]] = None
    usage: Optional[UserUsage] = None
    unread_notifications: Optional[int] = Field(
        None,
        alias="unreadNotifications",
        description="Number of unread notifications for the user",
    )


class UserSettingsUpdateConfig(CustomBaseModel):
    profile: Optional[UserSettingsProfileUpdateConfig] = None
    assistant: Optional[UserSettingsAssistantUpdateConfig] = None


class Notification(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of the notification")
    type: NotificationType
    message: str = Field(..., description="The message of the notification")
    status: NotificationStatus
    created_at: datetime = Field(
        ...,
        alias="createdAt",
        description="The UTC date and time when the notification has been created",
    )
    resource_uri: Optional[str] = Field(
        None,
        alias="resourceUri",
        description="The API service endpoint of the entity",
        examples=["/generators/94c77249-42bf-443a-8e17-6e18a19d60b8"],
    )


class GeneratorListItem(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a generator")
    name: Optional[str] = Field(None, description="The name of a generator")
    description: Optional[str] = Field(
        None, description="The description of a generator"
    )
    training_status: ProgressStatus = Field(..., alias="trainingStatus")
    training_time: Optional[datetime] = Field(
        None,
        alias="trainingTime",
        description="The UTC date and time when the training has finished.",
    )
    usage: Optional[GeneratorUsage] = None
    metadata: Metadata


class Probe(CustomBaseModel):
    name: Optional[str] = Field(None, description="The name of the table")
    rows: Optional[List[Dict[str, Any]]] = None


class GeneratorCloneConfig(CustomBaseModel):
    """
    The configuration for cloning a generator.
    """

    training_status: Optional[GeneratorCloneTrainingStatus] = Field(
        GeneratorCloneTrainingStatus.new, alias="trainingStatus"
    )


class ModelConfiguration(CustomBaseModel):
    """
    The training configuration for the AI model
    """

    model: Optional[str] = Field(
        None,
        description="The model to be used for training.",
        examples=[
            [
                "MOSTLY_AI/Small",
                "MOSTLY_AI/Medium",
                "MOSTLY_AI/Large",
                "MOSTLY_AI/LSTMFromScratch-3m",
                "microsoft/phi-1_5",
            ]
        ],
    )
    max_sample_size: Optional[int] = Field(
        None,
        alias="maxSampleSize",
        description="The maximum number of samples to consider for training.\nIf not provided, then all available samples will be taken.\n",
        ge=1,
        le=1000000000,
    )
    batch_size: Optional[int] = Field(
        None,
        alias="batchSize",
        description="The batch size used for training the model.\nIf not provided, batchSize will be chosen automatically.\n",
        ge=1,
        le=1000000,
    )
    max_training_time: Optional[int] = Field(
        10,
        alias="maxTrainingTime",
        description="The maximum number of minutes to train the model.",
        ge=0,
        le=100000,
    )
    max_epochs: Optional[int] = Field(
        100,
        alias="maxEpochs",
        description="The maximum number of epochs to train the model.",
        ge=0,
        le=100000,
    )
    max_sequence_window: Optional[int] = Field(
        100,
        alias="maxSequenceWindow",
        description="The maximum sequence window to consider for training.\nOnly applicable for TABULAR models.\n",
        ge=1,
        le=100000,
    )
    enable_flexible_generation: Optional[bool] = Field(
        True,
        alias="enableFlexibleGeneration",
        description="If true, then the trained generator can be used for rebalancing and imputation.\nOnly applicable for TABULAR models.\n",
    )
    value_protection: Optional[bool] = Field(
        True,
        alias="valueProtection",
        description="Defines if Rare Category, Extreme value, or Sequence length protection will be applied.\n",
    )
    rare_category_replacement_method: Optional[RareCategoryReplacementMethod] = Field(
        RareCategoryReplacementMethod.constant,
        alias="rareCategoryReplacementMethod",
        description="Specifies, if the rare categories for categoricals will be replaced by a constant\n_RARE_ or by a sample from non-rare categories.\nOnly applicable if valueProtection is set to True.\n",
    )
    differential_privacy: Optional[ModelConfigurationDifferentialPrivacy] = Field(
        None, alias="differentialPrivacy"
    )
    compute: Optional[str] = None


class ProgressStep(CustomBaseModel):
    id: Optional[str] = None
    model_label: Optional[str] = Field(
        None,
        alias="modelLabel",
        description="The unique label for the model, consisting of table name and a suffix for the model type.\nThis will be empty for steps that are not related to a model.\n",
        examples=[["census:tabular", "census:language"]],
    )
    compute_name: Optional[str] = Field(None, alias="computeName")
    restarts: Optional[int] = Field(
        None, description="Number of previous restarts for the corresponding task."
    )
    step_code: Optional[StepCode] = Field(None, alias="stepCode")
    start_date: Optional[datetime] = Field(
        None,
        alias="startDate",
        description="The UTC date and time when the job has started.\nIf the job has not started yet, then this is None.\n",
        examples=["2024-01-25T12:34:56Z"],
    )
    end_date: Optional[datetime] = Field(
        None,
        alias="endDate",
        description="The UTC date and time when the job has ended.\nIf the job is still, then this is None.\n",
        examples=["2024-01-25T12:34:56Z"],
    )
    messages: Optional[List[Dict[str, Any]]] = None
    error_message: Optional[str] = Field(None, alias="errorMessage")
    progress: Optional[ProgressValue] = None
    status: Optional[ProgressStatus] = None


class SyntheticTableConfiguration(CustomBaseModel):
    """
    The sample configuration for a synthetic table
    """

    sample_size: Optional[int] = Field(
        None,
        alias="sampleSize",
        description="Number of generated samples. Only applicable for subject tables.\nIf neither size nor seed is provided, then the default behavior for Synthetic Datasets is to generate the\nsame size of samples as the original, and the default behavior for Synthetic Datasets is to generate one\nsubject only.\n",
        ge=1,
    )
    sample_seed_connector_id: Optional[str] = Field(
        None,
        alias="sampleSeedConnectorId",
        description="The connector id of the seed data for conditional generation.\nOnly applicable for subject tables.\n",
    )
    sample_seed_dict: Optional[str] = Field(
        None,
        alias="sampleSeedDict",
        description="The base64-encoded string derived from a json line file containing the specified sample seed data.\n",
    )
    sample_seed_data: Optional[str] = Field(
        None,
        alias="sampleSeedData",
        description="The base64-encoded string derived from a Parquet file containing the specified sample seed data.\n",
    )
    sampling_temperature: Optional[float] = Field(
        None,
        alias="samplingTemperature",
        description="temperature for sampling",
        ge=0.0,
        le=2.0,
    )
    sampling_top_p: Optional[float] = Field(
        None, alias="samplingTopP", description="topP for sampling", ge=0.9, le=1.0
    )
    rebalancing: Optional[SyntheticTableRebalancing] = None
    imputation: Optional[List[str]] = Field(
        None,
        description="Specify a list of column names that are to be imputed.\nImputed columns will suppress the sampling of NULL values.\n",
    )
    fairness: Optional[SyntheticTableFairness] = None
    tabular_compute: Optional[str] = Field(None, alias="tabularCompute")
    language_compute: Optional[str] = Field(None, alias="languageCompute")

    @field_validator("sample_seed_dict", mode="before")
    @classmethod
    def validate_dict_before(cls, value):
        return (
            convert_to_base64(value, format="jsonl")
            if isinstance(value, dict)
            else value
        )

    @field_validator("sample_seed_data", mode="before")
    @classmethod
    def validate_data_before(cls, value):
        return convert_to_base64(value) if isinstance(value, pd.DataFrame) else value


class SyntheticTable(CustomBaseModel):
    id: Optional[str] = Field(
        None, description="The unique identifier of a synthetic table"
    )
    name: Optional[str] = Field(
        None,
        description="The name of a source table. It must be unique within a generator.",
    )
    configuration: Optional[SyntheticTableConfiguration] = None
    model_metrics: Optional[ModelMetrics] = Field(None, alias="modelMetrics")
    language_model_metrics: Optional[ModelMetrics] = Field(
        None, alias="languageModelMetrics"
    )
    foreign_keys: Optional[List[ForeignKey]] = Field(
        None, alias="foreignKeys", description="The foreign keys of this table."
    )
    total_rows: Optional[int] = Field(
        None,
        alias="totalRows",
        description="The total number of rows for that table in the generated synthetic dataset.\n",
    )
    total_datapoints: Optional[int] = Field(
        None,
        alias="totalDatapoints",
        description="The total number of datapoints for that table in the generated synthetic dataset.\n",
    )
    source_table_total_rows: Optional[int] = Field(
        None,
        alias="sourceTableTotalRows",
        description="The total number of rows in the source table while fetching data for training.\n",
    )


class SyntheticTablePatchConfig(CustomBaseModel):
    configuration: Optional[SyntheticTableConfiguration] = None


class SyntheticTableConfig(CustomBaseModel):
    name: Optional[str] = Field(
        None,
        description="The name of a synthetic table. This matches the name of a corresponding SourceTable.",
    )
    configuration: Optional[SyntheticTableConfiguration] = None


class AssistantThreadListItem(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a assistant thread")
    metadata: Metadata
    name: Optional[str] = Field(None, description="The name of a assistant thread")
    usage: Optional[AssistantThreadUsage] = None


class AssistantThread(CustomBaseModel):
    id: Optional[str] = Field(
        None, description="The unique identifier of a assistant thread"
    )
    metadata: Optional[Metadata] = None
    name: Optional[str] = Field(None, description="The name of a assistant thread")
    session_status: Optional[AssistantThreadSessionStatus] = Field(
        None, alias="sessionStatus"
    )
    messages: Optional[List[AssistantMessage]] = Field(
        None,
        description="List of all existing messages, excluding any system message.\nExample:\n  What's the square root of 9?   role: user        type: text\n  ok, I will write some python   role: assistant   type: text\n  r = math.sqrt(9)\\nr            role: assistant   type: python\n  3                              role: tool        type: console\n  The answer is 3!               role: assistant   type: text\n  Plot me a random barplot       role: user        type: text\n  ... plt.savefig() ...          role: assistant   type: python\n  Here is ![img]() ...           role: assistant   type: text\n  Write me a random file         role: user        type: text\n  ... .to_csv() ...              role: assistant   type: python\n  Here is [file]() ...           role: assistant   type: text\n",
    )
    usage: Optional[AssistantThreadUsage] = None


class Share(User):
    permission_level: Optional[PermissionLevel] = Field(None, alias="permissionLevel")


class ResourceShares(CustomBaseModel):
    is_public: Optional[bool] = Field(None, alias="isPublic")
    shares: Optional[List[Share]] = None


class SourceTable(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a source table")
    source_connector: Optional[BaseResource] = Field(None, alias="sourceConnector")
    location: Optional[str] = Field(
        None,
        description="The location of a source table. Together with the source connector it uniquely\nidentifies a source, and samples data from there.\n",
    )
    name: str = Field(
        ...,
        description="The name of a source table. It must be unique within a generator.",
    )
    primary_key: Optional[str] = Field(
        None, alias="primaryKey", description="The column name of the primary key"
    )
    columns: List[SourceColumn] = Field(
        ..., description="The columns of this generator table."
    )
    foreign_keys: Optional[List[SourceForeignKey]] = Field(
        None, alias="foreignKeys", description="The foreign keys of a table."
    )
    model_metrics: Optional[ModelMetrics] = Field(None, alias="modelMetrics")
    language_model_metrics: Optional[ModelMetrics] = Field(
        None, alias="languageModelMetrics"
    )
    model_configuration: Optional[ModelConfiguration] = Field(
        None, alias="modelConfiguration"
    )
    language_model_configuration: Optional[ModelConfiguration] = Field(
        None, alias="languageModelConfiguration"
    )
    total_rows: Optional[int] = Field(
        None,
        alias="totalRows",
        description="The total number of rows in the source table while fetching data for training.\n",
    )

    def model_qa_report(self):
        if self.client and hasattr(self.client, "model_qa_report"):
            return self.client.model_qa_report(
                generator_id=self.extra_key_values["generator_id"], table_id=self.id
            )

    def model_samples(self, **kwargs):
        if self.client and hasattr(self.client, "model_samples"):
            return self.client.model_qa_report(
                generator_id=self.extra_key_values["generator_id"],
                table_id=self.id,
                **kwargs,
            )

    def get_column(self, column_id: str):
        if self.client and hasattr(self.client, "get_column"):
            return self.client.get_column(
                generator_id=self.extra_key_values["generator_id"],
                table_id=self.id,
                column_id=column_id,
            )

    def create_foreign_key(self, **kwargs):
        if self.client and hasattr(self.client, "create_foreign_key"):
            return self.client.create_foreign_key(
                generator_id=self.extra_key_values["generator_id"],
                table_id=self.id,
                **kwargs,
            )

    def update_foreign_key(self, **kwargs):
        if self.client and hasattr(self.client, "update_foreign_key"):
            return self.client.update_foreign_key(
                generator_id=self.extra_key_values["generator_id"],
                table_id=self.id,
                **kwargs,
            )

    def delete_foreign_key(self, **kwargs):
        if self.client and hasattr(self.client, "delete_foreign_key"):
            return self.client.delete_foreign_key(
                generator_id=self.extra_key_values["generator_id"],
                table_id=self.id,
                **kwargs,
            )


class SourceTableConfig(CustomBaseModel):
    name: Optional[str] = Field(
        None,
        description="The name of a source table. It must be unique within a generator.",
    )
    source_connector_id: Optional[str] = Field(
        None,
        alias="sourceConnectorId",
        description="The unique identifier of a connector",
    )
    location: Optional[str] = Field(
        None,
        description="The location of a source table. Together with the source connector it uniquely\nidentifies a source, and samples data from there.\n",
    )
    data: Optional[str] = Field(
        None,
        description="The base64-encoded string derived from a Parquet file containing the specified source table.\n",
    )
    model_configuration: Optional[ModelConfiguration] = Field(
        None, alias="modelConfiguration"
    )
    language_model_configuration: Optional[ModelConfiguration] = Field(
        None, alias="languageModelConfiguration"
    )
    primary_key: Optional[str] = Field(
        None, alias="primaryKey", description="The column name of the primary key"
    )
    foreign_keys: Optional[List[SourceForeignKeyConfig]] = Field(
        None,
        alias="foreignKeys",
        description="The foreign key configurations of this table.",
    )
    columns: Optional[List[SourceColumnConfig]] = Field(
        None, description="The column configurations of this table."
    )

    @field_validator("data", mode="before")
    @classmethod
    def validate_data_before(cls, value):
        return convert_to_base64(value) if isinstance(value, pd.DataFrame) else value


class SourceTablePatchConfig(CustomBaseModel):
    name: Optional[str] = Field(
        None,
        description="The name of a source table. It must be unique within a generator.",
    )
    primary_key: Optional[str] = Field(
        None, alias="primaryKey", description="The column name of the primary key"
    )
    model_configuration: Optional[ModelConfiguration] = Field(
        None, alias="modelConfiguration"
    )
    language_model_configuration: Optional[ModelConfiguration] = Field(
        None, alias="languageModelConfiguration"
    )


class SourceTableAddConfig(CustomBaseModel):
    source_connector_id: str = Field(
        ...,
        alias="sourceConnectorId",
        description="The unique identifier of a connector",
    )
    location: str = Field(
        ...,
        description="The location of a source table. Together with the source connector it uniquely\nidentifies a source, and samples data from there.\n",
    )
    name: Optional[str] = Field(
        None,
        description="The name of a source table. It must be unique within a generator.",
    )
    include_children: Optional[bool] = Field(
        None,
        alias="includeChildren",
        description="If true, all tables that are referenced by foreign keys will\nbe included. If false, only the selected table will be included.\n",
    )
    model_configuration: Optional[ModelConfiguration] = Field(
        None, alias="modelConfiguration"
    )
    language_model_configuration: Optional[ModelConfiguration] = Field(
        None, alias="languageModelConfiguration"
    )


class JobProgress(CustomBaseModel):
    id: Optional[str] = None
    start_date: Optional[datetime] = Field(
        None,
        alias="startDate",
        description="The UTC date and time when the job has started.\nIf the job has not started yet, then this is None.\n",
        examples=["2024-01-25T12:34:56Z"],
    )
    end_date: Optional[datetime] = Field(
        None,
        alias="endDate",
        description="The UTC date and time when the job has ended.\nIf the job is still, then this is None.\n",
        examples=["2024-01-25T12:34:56Z"],
    )
    progress: Optional[ProgressValue] = None
    status: Optional[ProgressStatus] = None
    steps: Optional[List[ProgressStep]] = None


class SyntheticDataset(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a synthetic dataset")
    generator: Optional[BaseResource] = None
    metadata: Metadata
    name: str = Field(..., description="The name of a synthetic dataset")
    description: Optional[str] = Field(
        None, description="The description of a synthetic dataset"
    )
    generation_status: ProgressStatus = Field(..., alias="generationStatus")
    generation_time: Optional[datetime] = Field(
        None,
        alias="generationTime",
        description="The UTC date and time when the generation has finished.",
    )
    tables: Optional[List[SyntheticTable]] = Field(
        None, description="The tables of this synthetic dataset."
    )
    delivery: Optional[SyntheticDatasetDelivery] = None
    accuracy: Optional[float] = Field(
        None,
        description="The overall accuracy of the trained generator.\nThis is the average of the overall accuracy scores of all trained models.\n",
    )
    usage: Optional[SyntheticDatasetUsage] = None
    OPEN_URL_PARTS: ClassVar[list] = ["d", "synthetic-datasets"]
    generation: Annotated[Optional[Any], Field(exclude=True)] = None

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.generation = self.Generation(self)

    def update(
        self,
        name: Optional[str] = None,
        description: Optional[str] = None,
        delivery: Optional[SyntheticDatasetDelivery] = None,
    ) -> None:
        """
        Update a synthetic dataset with specific parameters.

        Args:
            name: The name of the synthetic dataset.
            description: The description of the synthetic dataset.
            delivery: The delivery configuration for the synthetic dataset.
        """
        patch_config = SyntheticDatasetPatchConfig(
            name=name,
            description=description,
            delivery=delivery,
        )
        self.client._update(
            synthetic_dataset_id=self.id,
            config=patch_config.model_dump(exclude_none=True),
        )
        self.reload()

    def delete(self) -> None:
        """
        Delete the synthetic dataset.

        Returns:
            None
        """
        return self.client._delete(synthetic_dataset_id=self.id)

    def config(self) -> SyntheticDatasetConfig:
        """
        Retrieve writable synthetic dataset properties.

        Returns:
            SyntheticDatasetConfig: The synthetic dataset properties as a configuration object.
        """
        return self.client._config(synthetic_dataset_id=self.id)

    def download(
        self,
        format: SyntheticDatasetFormat = "PARQUET",
        file_path: Union[str, Path, None] = None,
    ) -> Path:
        """
        Download synthetic dataset and save to file.

        Args:
            format: The format of the synthetic dataset.
            file_path: The file path to save the synthetic dataset.

        Returns:
            The path to the saved file.
        """
        bytes, filename = self.client._download(
            synthetic_dataset_id=self.id,
            ds_format=format,
            short_lived_file_token=self.metadata.short_lived_file_token,
        )
        file_path = Path(file_path or ".")
        if file_path.is_dir():
            file_path = file_path / filename
        file_path.write_bytes(bytes)
        return file_path

    def data(
        self, return_type: Literal["auto", "dict"] = "auto"
    ) -> Union[pd.DataFrame, dict[str, pd.DataFrame]]:
        """
        Download synthetic dataset and return as dictionary of pandas DataFrames.

        Args:
            return_type (Literal["auto", "dict"]): The format of the returned data.

        Returns:
            Union[pd.DataFrame, dict[str, pd.DataFrame]]: The synthetic dataset as a dictionary of pandas DataFrames.
        """
        dfs = self.client._data(
            synthetic_dataset_id=self.id,
            short_lived_file_token=self.metadata.short_lived_file_token,
        )
        if return_type == "auto" and len(dfs) == 1:
            return list(dfs.values())[0]
        else:
            return dfs

    class Generation:
        def __init__(self, _synthetic_dataset: "SyntheticDataset"):
            self.synthetic_dataset = _synthetic_dataset

        def start(self) -> None:
            """
            Start the generation process.
            """
            self.synthetic_dataset.client._generation_start(self.synthetic_dataset.id)

        def cancel(self) -> None:
            """
            Cancel the generation process.
            """
            self.synthetic_dataset.client._generation_cancel(self.synthetic_dataset.id)
            self.synthetic_dataset.reload()

        def progress(self) -> JobProgress:
            """
            Retrieve the progress of the generation process.

            Returns:
                JobProgress: The progress of the generation process.
            """
            return self.synthetic_dataset.client._generation_progress(
                self.synthetic_dataset.id
            )

        def wait(self, progress_bar: bool = True, interval: float = 2) -> None:
            """
            Poll the generation progress and wait until the process is complete.

            Args:
                progress_bar: If true, displays a progress bar.
                interval: Interval in seconds to poll the job progress.
            """
            self.synthetic_dataset.client._generation_wait(
                self.synthetic_dataset.id, progress_bar=progress_bar, interval=interval
            )
            self.synthetic_dataset.reload()


class SyntheticDatasetConfig(CustomBaseModel):
    generator_id: Optional[str] = Field(
        None, alias="generatorId", description="The unique identifier of a generator"
    )
    name: Optional[str] = Field(None, description="The name of a synthetic dataset")
    description: Optional[str] = Field(
        None, description="The description of a synthetic dataset"
    )
    tables: Optional[List[SyntheticTableConfig]] = None
    delivery: Optional[SyntheticDatasetDelivery] = None


class SyntheticProbeConfig(CustomBaseModel):
    generator_id: Optional[str] = Field(
        None, alias="generatorId", description="The unique identifier of a generator"
    )
    tables: Optional[List[SyntheticTableConfig]] = None


class Generator(CustomBaseModel):
    id: str = Field(..., description="The unique identifier of a generator")
    name: Optional[str] = Field(None, description="The name of a generator")
    description: Optional[str] = Field(
        None, description="The description of a generator"
    )
    training_status: ProgressStatus = Field(..., alias="trainingStatus")
    training_time: Optional[datetime] = Field(
        None,
        alias="trainingTime",
        description="The UTC date and time when the training has finished.",
    )
    usage: Optional[GeneratorUsage] = None
    metadata: Metadata
    accuracy: Optional[float] = Field(
        None,
        description="The overall accuracy of the trained generator.\nThis is the average of the overall accuracy scores of all trained models.\n",
    )
    tables: Optional[List[SourceTable]] = Field(
        None, description="The tables of this generator"
    )
    OPEN_URL_PARTS: ClassVar[list] = ["d", "generators"]
    training: Annotated[Optional[Any], Field(exclude=True)] = None

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.training = self.Training(self)

    def update(
        self,
        name: Optional[str] = None,
        description: Optional[str] = None,
    ) -> None:
        """
        Update a generator with specific parameters.

        Args:
            name: The name of the generator.
            description: The description of the generator.
        """
        patch_config = GeneratorPatchConfig(
            name=name,
            description=description,
        )
        self.client._update(
            generator_id=self.id, config=patch_config.model_dump(exclude_none=True)
        )
        self.reload()

    def delete(self) -> None:
        """
        Delete the generator.

        Returns:
            None
        """
        return self.client._delete(generator_id=self.id)

    def config(self) -> GeneratorConfig:
        """
        Retrieve writable generator properties.

        Returns:
            GeneratorConfig: The generator properties as a configuration object.
        """
        return self.client._config(generator_id=self.id)

    def export_to_file(
        self,
        file_path: Union[str, Path, None] = None,
    ) -> Path:
        """
        Export generator and save to file.

        Args:
            file_path: The file path to save the generator.

        Returns:
            The path to the saved file.
        """
        bytes, filename = self.client._export_to_file(generator_id=self.id)
        file_path = Path(file_path or ".")
        if file_path.is_dir():
            file_path = file_path / filename
        file_path.write_bytes(bytes)
        return file_path

    def clone(self, training_status: Literal["NEW", "CONTINUE"] = "NEW") -> "Generator":
        """
        Clone the generator.

        Args:
            training_status (Literal["NEW", "CONTINUE"]): The training status of the cloned generator.

        Returns:
            Generator: The cloned generator object.
        """
        return self.client._clone(generator_id=self.id, training_status=training_status)

    class Training:
        def __init__(self, _generator: "Generator"):
            self.generator = _generator

        def start(self) -> None:
            """
            Start training.
            """
            self.generator.client._training_start(self.generator.id)

        def cancel(self) -> None:
            """
            Cancel training.
            """
            self.generator.client._training_cancel(self.generator.id)
            self.generator.reload()

        def progress(self) -> JobProgress:
            """
            Retrieve job progress of training.

            Returns:
                JobProgress: The job progress of the training process.
            """
            return self.generator.client._training_progress(self.generator.id)

        def wait(self, progress_bar: bool = True, interval: float = 2) -> None:
            """
            Poll training progress and loop until training has completed.

            Args:
                progress_bar: If true, displays the progress bar.
                interval: The interval in seconds to poll the job progress.
            """
            self.generator.client._training_wait(
                self.generator.id, progress_bar=progress_bar, interval=interval
            )
            self.generator.reload()


class GeneratorConfig(CustomBaseModel):
    """
    The configuration for creating a new generator.
    """

    name: Optional[str] = Field(None, description="The name of a generator")
    description: Optional[str] = Field(
        None, description="The description of a generator"
    )
    tables: Optional[List[SourceTableConfig]] = Field(
        None, description="The tables of a generator"
    )
